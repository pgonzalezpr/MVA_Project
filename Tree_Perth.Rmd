---
title: "Classification Tree - Perth"
author: "Kathryn Weissman"
date: "1/4/2022"
output: html_document
---

```{r clean workspace, echo=FALSE}
# Clean workspace
rm(list=ls())
```

# Classification Tree: Perth

The goal is to predict if there will be rain the following day.

```{r setup, include=FALSE}
# these are the libraries included in CART Lab
library(DAAG)
library(party)
library(rpart)
library(rpart.plot)
library(mlbench)
library(caret)
library(pROC)
library(tree)
library(C50)
library(printr)
library(randomForest)
```

```{r}
set.seed(1) # for reproducibility of results
```


## Load Train & Test Data

I am loading the same data that was used for the LDA modelling.

```{r load data}
# Load the data
Ptrain <- read.csv("Train_Test_CSVs/df_Perth_train.csv", stringsAsFactors = T)
Ptest <- read.csv("Train_Test_CSVs/df_Perth_test.csv", stringsAsFactors = T)
Ptrain$Date <- as.Date(Ptrain$Date)
Ptest$Date <- as.Date(Ptest$Date)
```

## Summarize Train Data
```{r}
str(Ptrain)
```
```{r}
summary(Ptrain)
```

## Summarize Test Data
```{r}
summary(Ptest)
```

## Compare Target Variables for Train and Test Data

It is important that our training data and testing data have similar characteristics to check the accuracy of our model.

```{r}
print ("Percentage of Days with Rain Tomorrow in Train Data")
round(prop.table(table(Ptrain$RainTomorrow))*100,1)
print ("Percentage of Days with Rain Tomorrow in Test Data")
round(prop.table(table(Ptest$RainTomorrow))*100,1)
```

```{r}
print ("Percentage of Days in each Season in Train Data")
round(prop.table(table(Ptrain$Season))*100,1)
print ("Percentage of Days in each Season in Test Data")
round(prop.table(table(Ptest$Season))*100,1)
```


## Classification Tree

<https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf>

"The rpart programs build classification or regression models of a very general structure using a two stage procedure; the resulting models can be represented as binary trees."

We use two different sets of modeling variables to see if there is a difference in the performance of the model for classifying whether or not there will be rain tomorrow.

```{r choose modeling variables}
# We use two different sets of variables for the model to consider

# Set 1 includes "RainToday" and "TempRange"
modeling_vars1 <- c("Evaporation", "Sunshine", "WindGustSpeed", "WindSpeed9am", 
                   "WindSpeed3pm", "Humidity9am", "Humidity3pm", "Pressure9am", 
                   "Pressure3pm", "Cloud9am", "Cloud3pm", "TempRange", 
                   "RainToday", "Season", "RainTomorrow")

# Set 2 includes all temperature variables and "Rainfall" instead of "RainToday"
modeling_vars2 <- c("Evaporation", "Sunshine", "WindGustSpeed", "WindSpeed9am",
                   "WindSpeed3pm", "Humidity9am", "Humidity3pm", "Pressure9am",
                   "Pressure3pm",  "Cloud9am", "Cloud3pm", "Temp9am", "Temp3pm",
                   "TempRange", "MaxTemp", "MinTemp", "Rainfall", "Season", 
                   "RainTomorrow")

train1 <- Ptrain[,modeling_vars1]
test1 <- Ptest[,modeling_vars1]

train2 <- Ptrain[,modeling_vars2]
test2 <- Ptest[,modeling_vars2]
```

### Using Fitting & Pruning Strategy shown in Lab
#### First Set of Variables


```{r}
# Best strategy for tree fitting, cp = 0
treeFit1 <- rpart(RainTomorrow ~., data = train1, method = "class", cp = 0) 
printcp(treeFit1)
plotcp(treeFit1)
rpart.plot(treeFit1)
```
```{r}
xerror <- treeFit1$cptable[,"xerror"]
imin.xerror <- which.min(xerror)
treeFit1$cptable[imin.xerror, ]
upper.xerror <- xerror[imin.xerror] + treeFit1$cptable[imin.xerror, "xstd"]
icp <- min(which(xerror <= upper.xerror))
cp <- treeFit1$cptable[icp, "CP"]
```

```{r}
tree1 <- prune(treeFit1, cp = cp)
rpart.plot(tree1)
```

```{r}
#Classification Rules
rpart.rules(tree1, style = "tall")
```

```{r}
#Checking important variables
importance1 <- tree1$variable.importance 
importance1 <- round(100*importance1/sum(importance1), 1)
importance1[importance1 >= 1]
```

### Confusion Matrix

Help for Confusion Matrix: <https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62>

Recall,Precision and Accuracy should be high as possible

Balanced Accuracy represents area under ROC.


```{r}
#Evaluation
#Confusion matrix-train
pred_train1 <- predict(tree1, train1, type = 'class') # using train data
#Make sure to state positive class in the confusion matrix.
confusionMatrix(pred_train1, train1$RainTomorrow, positive="Yes")
```

The sensitivity is very low, which is how accurate the predictions are for rainy days. Since the data is imbalanced, we should try using SMOTE sampling for the training data to see if it improves the performance of the model.

```{r}
#Test Evaluation
#Confusion matrix-test
pred_test1 <- predict(tree1, test1, type = 'class') # using test data
confusionMatrix(pred_test1, test1$RainTomorrow, positive="Yes")
```

#### Second Set of Variables

This set includes more variables than the first set.

```{r}
# Best strategy for tree fitting, cp = 0
treeFit2 <- rpart(RainTomorrow ~., data = train2, method = "class", cp = 0) 
printcp(treeFit2)
plotcp(treeFit2)
rpart.plot(treeFit2)
```
```{r}
xerror <- treeFit2$cptable[,"xerror"]
imin.xerror <- which.min(xerror)
treeFit2$cptable[imin.xerror, ]
upper.xerror <- xerror[imin.xerror] + treeFit2$cptable[imin.xerror, "xstd"]
icp <- min(which(xerror <= upper.xerror))
cp <- treeFit2$cptable[icp, "CP"]
```

After pruning, the trees using both sets of variables are the identical for Perth.

```{r}
tree2 <- prune(treeFit2, cp = cp)
rpart.plot(tree2)
```
```{r}
#Classification Rules
rpart.rules(tree2, style = "tall")
```


```{r}
#Checking important variables
importance2 <- tree2$variable.importance 
importance2 <- round(100*importance2/sum(importance2), 1)
importance2[importance2 >= 1]
```


```{r}
#Train Set Evaluation
#Confusion matrix-train
pred_train2 <- predict(tree2, train2, type = 'class') # using train data
#Make sure to state positive class in the confusion matrix.
confusionMatrix(pred_train2, train2$RainTomorrow, positive="Yes")
```

```{r}
#Test Set Evaluation
#Confusion matrix-test
pred_test2 <- predict(tree2, test2, type = 'class') # using test data
confusionMatrix(pred_test2, test2$RainTomorrow, positive="Yes")
```



